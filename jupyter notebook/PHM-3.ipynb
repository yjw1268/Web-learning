{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bearing1_2\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats,signal,fftpack\n",
    "import math\n",
    "from pywt import wavedec\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "params = {}\n",
    "params['data_path'] = 'Bearing1_2' #目标原始数据文件夹\n",
    "params['save_path'] = 'datafeature/datafeature1_2.csv' #目标输出文件位置\n",
    "\n",
    "argvs = ['data_path=Bearing1_2','save_path=datafeature/datafeature1_2.csv'] #与上面同步即可\n",
    "try:\n",
    "\n",
    "    for i in range(len(argvs)):\n",
    "        if i < 1:\n",
    "            continue\n",
    "        if argvs[i].split('=')[1] == 'None':\n",
    "            params[argvs[i].split('=')[0]] = None\n",
    "        else:\n",
    "            Type = type(params[argvs[i].split('=')[0]])\n",
    "            params[argvs[i].split('=')[0]] = Type(argvs[i].split('=')[1])\n",
    "\n",
    "    columns_list=['time_mean','time_std','time_max','time_min','time_rms','time_ptp','time_median','time_iqr','time_pr','time_skew','time_kurtosis','time_var','time_amp',                'time_smr','time_wavefactor','time_peakfactor','time_pulse','time_margin','freq_mean','freq_std','freq_max','freq_min','freq_rms','freq_median',               'freq_iqr','freq_pr','freq_f2','freq_f3','freq_f4','freq_f5','freq_f6','freq_f7','freq_f8','ener_cA5','ener_cD1','ener_cD2','ener_cD3','ener_cD4',        'ener_cD5','ratio_cA5','ratio_cD1','ratio_cD2','ratio_cD3','ratio_cD4','ratio_cD5']\n",
    "    columns_list1 = [a + '_vibX' for a in columns_list]\n",
    "    columns_list2 = [a + '_vibY' for a in columns_list]\n",
    "    columns_list_final = columns_list1 + columns_list2\n",
    "#特征提取函数，注意函数的输入参数为csv文件的路径\n",
    "    def feature_get(filepath):\n",
    "        col = ['1','2','3','4','vib_x','vib_y']\n",
    "        dfs = pd.DataFrame(pd.read_csv(filepath,names = col))\n",
    "        df = dfs.loc[:,['vib_x','vib_y']]\n",
    "        feature_list = []\n",
    "        for i in df.columns:\n",
    "            #----------  time-domain feature,18\n",
    "            #依次为均值，标准差，最大值，最小值，均方根，峰峰值，中位数，四分位差，百分位差，偏度，峰度，方差，整流平均值，方根幅值，波形因子，峰值因子，脉冲值，裕度\n",
    "            df_line = df[i]\n",
    "            time_mean = df_line.mean()\n",
    "            time_std = df_line.std()\n",
    "            time_max = df_line.max()\n",
    "            time_min = df_line.min()\n",
    "            time_rms = np.sqrt(np.square(df_line).mean())\n",
    "            time_ptp = time_max-time_min \n",
    "            time_median = np.median(df_line)\n",
    "            time_iqr = np.percentile(df_line,75)-np.percentile(df_line,25)\n",
    "            time_pr = np.percentile(df_line,90)-np.percentile(df_line,10)\n",
    "            time_skew = stats.skew(df_line)\n",
    "            time_kurtosis = stats.kurtosis(df_line)\n",
    "            time_var = np.var(df_line)\n",
    "            time_amp = np.abs(df_line).mean()\n",
    "            time_smr = np.square(np.sqrt(np.abs(df_line)).mean())\n",
    "            #下面四个特征需要注意分母为0或接近0问题，可能会发生报错\n",
    "            time_wavefactor = time_rms/time_amp\n",
    "            time_peakfactor = time_max/time_rms\n",
    "            time_pulse = time_max/time_amp\n",
    "            time_margin = time_max/time_smr\n",
    "            #----------  freq-domain feature,15\n",
    "            #采样频率25600Hz\n",
    "            df_fftline = fftpack.fft(df[i])\n",
    "            freq_fftline = fftpack.fftfreq(len(df[i]),1/25600)\n",
    "            df_fftline = abs(df_fftline[freq_fftline>=0])\n",
    "            freq_fftline = freq_fftline[freq_fftline>=0]\n",
    "            #基本特征,依次为均值，标准差，最大值，最小值，均方根，中位数，四分位差，百分位差\n",
    "            freq_mean = df_fftline.mean()\n",
    "            freq_std = df_fftline.std()\n",
    "            freq_max = df_fftline.max()\n",
    "            freq_min = df_fftline.min()\n",
    "            freq_rms = np.sqrt(np.square(df_fftline).mean())\n",
    "            freq_median = np.median(df_fftline)\n",
    "            freq_iqr = np.percentile(df_fftline,75)-np.percentile(df_fftline,25)\n",
    "            freq_pr = np.percentile(df_fftline,90)-np.percentile(df_fftline,10)\n",
    "            #f2 f3 f4反映频谱集中程度\n",
    "            freq_f2 = np.square((df_fftline-freq_mean)).sum()/(len(df_fftline)-1)\n",
    "            freq_f3 = pow((df_fftline-freq_mean),3).sum()/(len(df_fftline)*pow(freq_f2,1.5))\n",
    "            freq_f4 = pow((df_fftline-freq_mean),4).sum()/(len(df_fftline)*pow(freq_f2,2))\n",
    "            #f5 f6 f7 f8反映主频带位置\n",
    "            freq_f5 = np.multiply(freq_fftline,df_fftline).sum()/df_fftline.sum()\n",
    "            freq_f6 = np.sqrt(np.multiply(np.square(freq_fftline),df_fftline).sum())/df_fftline.sum()\n",
    "            freq_f7 = np.sqrt(np.multiply(pow(freq_fftline,4),df_fftline).sum())/np.multiply(np.square(freq_fftline),df_fftline).sum()\n",
    "            freq_f8 = np.multiply(np.square(freq_fftline),df_fftline).sum()/np.sqrt(np.multiply(pow(freq_fftline,4),df_fftline).sum()*df_fftline.sum())\n",
    "            #----------  timefreq-domain feature,12\n",
    "            #5级小波变换，最后输出6个能量特征和其归一化能量特征\n",
    "            cA5, cD5, cD4, cD3, cD2, cD1 = wavedec(df[i], 'db10', level=5)\n",
    "            ener_cA5 = np.square(cA5).sum()\n",
    "            ener_cD5 = np.square(cD5).sum()\n",
    "            ener_cD4 = np.square(cD4).sum()\n",
    "            ener_cD3 = np.square(cD3).sum()\n",
    "            ener_cD2 = np.square(cD2).sum()\n",
    "            ener_cD1 = np.square(cD1).sum()\n",
    "            ener = ener_cA5 + ener_cD1 + ener_cD2 + ener_cD3 + ener_cD4 + ener_cD5\n",
    "            ratio_cA5 = ener_cA5/ener\n",
    "            ratio_cD5 = ener_cD5/ener\n",
    "            ratio_cD4 = ener_cD4/ener\n",
    "            ratio_cD3 = ener_cD3/ener\n",
    "            ratio_cD2 = ener_cD2/ener\n",
    "            ratio_cD1 = ener_cD1/ener\n",
    "            feature_list.extend([time_mean,time_std,time_max,time_min,time_rms,time_ptp,time_median,time_iqr,time_pr,time_skew,time_kurtosis,time_var,time_amp,\n",
    "                             time_smr,time_wavefactor,time_peakfactor,time_pulse,time_margin,freq_mean,freq_std,freq_max,freq_min,freq_rms,freq_median,\n",
    "                             freq_iqr,freq_pr,freq_f2,freq_f3,freq_f4,freq_f5,freq_f6,freq_f7,freq_f8,ener_cA5,ener_cD1,ener_cD2,ener_cD3,ener_cD4,ener_cD5,\n",
    "                             ratio_cA5,ratio_cD1,ratio_cD2,ratio_cD3,ratio_cD4,ratio_cD5])\n",
    "\n",
    "        return feature_list\n",
    "\n",
    "    files_path = params['data_path']\n",
    "    print(files_path)\n",
    "    filelists = os.listdir(files_path) #读取文件，得到文件夹中所有csv文件名\n",
    "    filelists.sort(key=lambda x:int(x[4:-4])) #按照文件名数字由小到大排序\n",
    "    features = []\n",
    "#循环读取文件夹中每个csv文件，对每个csv文件进行特征提取\n",
    "    for info in filelists:\n",
    "        file_path = os.path.join(files_path,info)\n",
    "        #print(file_path)\n",
    "        fea = feature_get(file_path)\n",
    "        features.append(fea)\n",
    "    result = pd.DataFrame(features,columns = columns_list_final)\n",
    "    result.to_csv(params['save_path'], sep=',', header=True, index=False)\n",
    "    print(\"Done.\")\n",
    "    #print(result.shape)\n",
    "except Exception as e:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = 'datafeature/datafeature1_2.csv'  #特征提取后的csv文件路径\n",
    "df = pd.DataFrame(pd.read_csv(path))\n",
    "delete_features = ['time_mean_vibX','time_std_vibX'] #需要删除的列名自行加到数组里\n",
    "df = df.drop(delete_features, axis=1) #特征选择之后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#import xgboost as xgb\n",
    "from matplotlib import pyplot\n",
    "import lightgbm as lgb\n",
    "#from xgboost import plot_importance\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "import json\n",
    "import traceback\n",
    "\n",
    "traindata_path = 'DATA/Bearing1_1_fea.csv'\n",
    "testdata_path = 'DATA/Bearing1_7_fea.csv'\n",
    "\n",
    "data1 = pd.DataFrame(pd.read_csv(traindata_path))\n",
    "data7 = pd.DataFrame(pd.read_csv(testdata_path))\n",
    "\n",
    "X1 = data1.drop(['Label'], axis=1) \n",
    "X7 = data7.drop(['Label'], axis=1)\n",
    "\n",
    "Y1 = data1.loc[:,['Label']] \n",
    "Y7 = data7.loc[:,['Label']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler()\n",
    "X1_scaler =  X_scaler.fit_transform(X1)\n",
    "X7_scaler =  X_scaler.fit_transform(X7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1_scaler, Y1, test_size=0.3, random_state=123)#划分训练和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train['Label'].values)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test['Label'].values, reference=lgb_train)\n",
    "\n",
    "# 将参数写成字典下形式\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',  # 设置提升类型\n",
    "    'objective': 'regression', # 目标函数\n",
    "    'metric': 'rmse',  # 评估函数\n",
    "    'num_leaves': 126,   # 叶子节点数\n",
    "    'learning_rate': 0.05,  # 学习速率\n",
    "    'feature_fraction': 0.9, # 建树的特征选择比例\n",
    "    'bagging_fraction': 0.8, # 建树的样本采样比例\n",
    "    'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging\n",
    "    'verbose': 1 # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 7747.22\tvalid_1's rmse: 7547.99\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 7361.5\tvalid_1's rmse: 7170.19\n",
      "[3]\ttraining's rmse: 6996.55\tvalid_1's rmse: 6812.73\n",
      "[4]\ttraining's rmse: 6648.32\tvalid_1's rmse: 6472.26\n",
      "[5]\ttraining's rmse: 6317.9\tvalid_1's rmse: 6148.97\n",
      "[6]\ttraining's rmse: 6003.96\tvalid_1's rmse: 5841.74\n",
      "[7]\ttraining's rmse: 5705.89\tvalid_1's rmse: 5550.58\n",
      "[8]\ttraining's rmse: 5422.76\tvalid_1's rmse: 5274.24\n",
      "[9]\ttraining's rmse: 5154.05\tvalid_1's rmse: 5011.25\n",
      "[10]\ttraining's rmse: 4898.63\tvalid_1's rmse: 4763.11\n",
      "[11]\ttraining's rmse: 4656.06\tvalid_1's rmse: 4526.62\n",
      "[12]\ttraining's rmse: 4425.43\tvalid_1's rmse: 4302.33\n",
      "[13]\ttraining's rmse: 4206.79\tvalid_1's rmse: 4089.73\n",
      "[14]\ttraining's rmse: 3999.08\tvalid_1's rmse: 3888.51\n",
      "[15]\ttraining's rmse: 3801.69\tvalid_1's rmse: 3697.36\n",
      "[16]\ttraining's rmse: 3614.11\tvalid_1's rmse: 3515.79\n",
      "[17]\ttraining's rmse: 3435.92\tvalid_1's rmse: 3343.67\n",
      "[18]\ttraining's rmse: 3266.72\tvalid_1's rmse: 3179.93\n",
      "[19]\ttraining's rmse: 3106.02\tvalid_1's rmse: 3025.75\n",
      "[20]\ttraining's rmse: 2953.58\tvalid_1's rmse: 2878.9\n",
      "[21]\ttraining's rmse: 2808.71\tvalid_1's rmse: 2739.19\n",
      "[22]\ttraining's rmse: 2671.4\tvalid_1's rmse: 2608.31\n",
      "[23]\ttraining's rmse: 2540.77\tvalid_1's rmse: 2484.27\n",
      "[24]\ttraining's rmse: 2416.95\tvalid_1's rmse: 2366.77\n",
      "[25]\ttraining's rmse: 2299.13\tvalid_1's rmse: 2255.23\n",
      "[26]\ttraining's rmse: 2187.49\tvalid_1's rmse: 2149.59\n",
      "[27]\ttraining's rmse: 2081.43\tvalid_1's rmse: 2049.21\n",
      "[28]\ttraining's rmse: 1980.83\tvalid_1's rmse: 1954.55\n",
      "[29]\ttraining's rmse: 1885.28\tvalid_1's rmse: 1865.59\n",
      "[30]\ttraining's rmse: 1794.64\tvalid_1's rmse: 1781.23\n",
      "[31]\ttraining's rmse: 1708.39\tvalid_1's rmse: 1702.3\n",
      "[32]\ttraining's rmse: 1626.45\tvalid_1's rmse: 1626.59\n",
      "[33]\ttraining's rmse: 1548.7\tvalid_1's rmse: 1555.12\n",
      "[34]\ttraining's rmse: 1474.92\tvalid_1's rmse: 1487.92\n",
      "[35]\ttraining's rmse: 1404.9\tvalid_1's rmse: 1424.51\n",
      "[36]\ttraining's rmse: 1338.51\tvalid_1's rmse: 1365.46\n",
      "[37]\ttraining's rmse: 1275.43\tvalid_1's rmse: 1309.96\n",
      "[38]\ttraining's rmse: 1215.74\tvalid_1's rmse: 1257.8\n",
      "[39]\ttraining's rmse: 1159.16\tvalid_1's rmse: 1208.56\n",
      "[40]\ttraining's rmse: 1105.32\tvalid_1's rmse: 1162.83\n",
      "[41]\ttraining's rmse: 1054.32\tvalid_1's rmse: 1119.49\n",
      "[42]\ttraining's rmse: 1006.13\tvalid_1's rmse: 1079.16\n",
      "[43]\ttraining's rmse: 960.502\tvalid_1's rmse: 1041.69\n",
      "[44]\ttraining's rmse: 917.47\tvalid_1's rmse: 1006.92\n",
      "[45]\ttraining's rmse: 876.64\tvalid_1's rmse: 974.444\n",
      "[46]\ttraining's rmse: 837.746\tvalid_1's rmse: 944.852\n",
      "[47]\ttraining's rmse: 801.095\tvalid_1's rmse: 917.24\n",
      "[48]\ttraining's rmse: 766.457\tvalid_1's rmse: 891.537\n",
      "[49]\ttraining's rmse: 733.527\tvalid_1's rmse: 868.679\n",
      "[50]\ttraining's rmse: 702.614\tvalid_1's rmse: 847.304\n",
      "[51]\ttraining's rmse: 673.565\tvalid_1's rmse: 826.814\n",
      "[52]\ttraining's rmse: 646.1\tvalid_1's rmse: 807.914\n",
      "[53]\ttraining's rmse: 620.061\tvalid_1's rmse: 790.626\n",
      "[54]\ttraining's rmse: 595.72\tvalid_1's rmse: 774.697\n",
      "[55]\ttraining's rmse: 572.532\tvalid_1's rmse: 760.344\n",
      "[56]\ttraining's rmse: 550.418\tvalid_1's rmse: 747.681\n",
      "[57]\ttraining's rmse: 529.577\tvalid_1's rmse: 736.048\n",
      "[58]\ttraining's rmse: 509.989\tvalid_1's rmse: 724.813\n",
      "[59]\ttraining's rmse: 491.401\tvalid_1's rmse: 714.882\n",
      "[60]\ttraining's rmse: 473.963\tvalid_1's rmse: 705.711\n",
      "[61]\ttraining's rmse: 457.531\tvalid_1's rmse: 697.006\n",
      "[62]\ttraining's rmse: 441.862\tvalid_1's rmse: 689.126\n",
      "[63]\ttraining's rmse: 427.294\tvalid_1's rmse: 681.696\n",
      "[64]\ttraining's rmse: 413.506\tvalid_1's rmse: 675.26\n",
      "[65]\ttraining's rmse: 400.639\tvalid_1's rmse: 669.556\n",
      "[66]\ttraining's rmse: 388.287\tvalid_1's rmse: 664.265\n",
      "[67]\ttraining's rmse: 376.755\tvalid_1's rmse: 659.544\n",
      "[68]\ttraining's rmse: 365.787\tvalid_1's rmse: 656.166\n",
      "[69]\ttraining's rmse: 355.54\tvalid_1's rmse: 652.325\n",
      "[70]\ttraining's rmse: 345.994\tvalid_1's rmse: 649.099\n",
      "[71]\ttraining's rmse: 336.715\tvalid_1's rmse: 645.943\n",
      "[72]\ttraining's rmse: 328.111\tvalid_1's rmse: 643.11\n",
      "[73]\ttraining's rmse: 320.047\tvalid_1's rmse: 640.175\n",
      "[74]\ttraining's rmse: 312.578\tvalid_1's rmse: 638.114\n",
      "[75]\ttraining's rmse: 305.245\tvalid_1's rmse: 635.793\n",
      "[76]\ttraining's rmse: 298.414\tvalid_1's rmse: 633.88\n",
      "[77]\ttraining's rmse: 291.853\tvalid_1's rmse: 632.256\n",
      "[78]\ttraining's rmse: 285.955\tvalid_1's rmse: 630.726\n",
      "[79]\ttraining's rmse: 280.306\tvalid_1's rmse: 629.351\n",
      "[80]\ttraining's rmse: 274.774\tvalid_1's rmse: 628.322\n",
      "[81]\ttraining's rmse: 269.467\tvalid_1's rmse: 627.624\n",
      "[82]\ttraining's rmse: 264.814\tvalid_1's rmse: 627.132\n",
      "[83]\ttraining's rmse: 260.227\tvalid_1's rmse: 626.13\n",
      "[84]\ttraining's rmse: 255.909\tvalid_1's rmse: 625.184\n",
      "[85]\ttraining's rmse: 251.919\tvalid_1's rmse: 624.684\n",
      "[86]\ttraining's rmse: 248.056\tvalid_1's rmse: 623.887\n",
      "[87]\ttraining's rmse: 244.068\tvalid_1's rmse: 622.781\n",
      "[88]\ttraining's rmse: 240.657\tvalid_1's rmse: 622.193\n",
      "[89]\ttraining's rmse: 237.247\tvalid_1's rmse: 621.455\n",
      "[90]\ttraining's rmse: 233.908\tvalid_1's rmse: 620.728\n",
      "[91]\ttraining's rmse: 230.682\tvalid_1's rmse: 620.367\n",
      "[92]\ttraining's rmse: 227.757\tvalid_1's rmse: 619.704\n",
      "[93]\ttraining's rmse: 224.726\tvalid_1's rmse: 619.481\n",
      "[94]\ttraining's rmse: 221.956\tvalid_1's rmse: 618.916\n",
      "[95]\ttraining's rmse: 219.257\tvalid_1's rmse: 618.182\n",
      "[96]\ttraining's rmse: 216.671\tvalid_1's rmse: 617.636\n",
      "[97]\ttraining's rmse: 214.31\tvalid_1's rmse: 617.522\n",
      "[98]\ttraining's rmse: 212.009\tvalid_1's rmse: 617.336\n",
      "[99]\ttraining's rmse: 209.593\tvalid_1's rmse: 617.026\n",
      "[100]\ttraining's rmse: 207.598\tvalid_1's rmse: 616.634\n",
      "[101]\ttraining's rmse: 205.368\tvalid_1's rmse: 616.581\n",
      "[102]\ttraining's rmse: 203.276\tvalid_1's rmse: 616.432\n",
      "[103]\ttraining's rmse: 201.386\tvalid_1's rmse: 616.512\n",
      "[104]\ttraining's rmse: 199.47\tvalid_1's rmse: 616.53\n",
      "[105]\ttraining's rmse: 197.752\tvalid_1's rmse: 616.868\n",
      "[106]\ttraining's rmse: 195.644\tvalid_1's rmse: 616.434\n",
      "[107]\ttraining's rmse: 193.692\tvalid_1's rmse: 616.26\n",
      "[108]\ttraining's rmse: 191.823\tvalid_1's rmse: 616.178\n",
      "[109]\ttraining's rmse: 189.998\tvalid_1's rmse: 616.177\n",
      "[110]\ttraining's rmse: 188.075\tvalid_1's rmse: 616.201\n",
      "[111]\ttraining's rmse: 186.417\tvalid_1's rmse: 615.864\n",
      "[112]\ttraining's rmse: 184.676\tvalid_1's rmse: 615.781\n",
      "[113]\ttraining's rmse: 183.186\tvalid_1's rmse: 615.321\n",
      "[114]\ttraining's rmse: 181.6\tvalid_1's rmse: 615.216\n",
      "[115]\ttraining's rmse: 180.253\tvalid_1's rmse: 614.942\n",
      "[116]\ttraining's rmse: 178.654\tvalid_1's rmse: 614.975\n",
      "[117]\ttraining's rmse: 177.073\tvalid_1's rmse: 615.002\n",
      "[118]\ttraining's rmse: 175.587\tvalid_1's rmse: 615.026\n",
      "[119]\ttraining's rmse: 174.222\tvalid_1's rmse: 614.604\n",
      "[120]\ttraining's rmse: 173.02\tvalid_1's rmse: 614.255\n",
      "[121]\ttraining's rmse: 171.305\tvalid_1's rmse: 614.355\n",
      "[122]\ttraining's rmse: 169.774\tvalid_1's rmse: 614.272\n",
      "[123]\ttraining's rmse: 168.421\tvalid_1's rmse: 614.154\n",
      "[124]\ttraining's rmse: 166.86\tvalid_1's rmse: 614.147\n",
      "[125]\ttraining's rmse: 165.535\tvalid_1's rmse: 614.425\n",
      "[126]\ttraining's rmse: 164.15\tvalid_1's rmse: 614.23\n",
      "[127]\ttraining's rmse: 162.751\tvalid_1's rmse: 614.084\n",
      "[128]\ttraining's rmse: 161.471\tvalid_1's rmse: 613.789\n",
      "[129]\ttraining's rmse: 160.259\tvalid_1's rmse: 613.785\n",
      "[130]\ttraining's rmse: 158.928\tvalid_1's rmse: 613.686\n",
      "[131]\ttraining's rmse: 157.488\tvalid_1's rmse: 613.398\n",
      "[132]\ttraining's rmse: 156.042\tvalid_1's rmse: 613.128\n",
      "[133]\ttraining's rmse: 154.735\tvalid_1's rmse: 612.96\n",
      "[134]\ttraining's rmse: 153.543\tvalid_1's rmse: 612.668\n",
      "[135]\ttraining's rmse: 152.403\tvalid_1's rmse: 612.34\n",
      "[136]\ttraining's rmse: 151.168\tvalid_1's rmse: 611.907\n",
      "[137]\ttraining's rmse: 149.831\tvalid_1's rmse: 611.609\n",
      "[138]\ttraining's rmse: 148.685\tvalid_1's rmse: 611.593\n",
      "[139]\ttraining's rmse: 147.396\tvalid_1's rmse: 611.557\n",
      "[140]\ttraining's rmse: 146.315\tvalid_1's rmse: 611.605\n",
      "[141]\ttraining's rmse: 145.193\tvalid_1's rmse: 611.338\n",
      "[142]\ttraining's rmse: 144.062\tvalid_1's rmse: 611.33\n",
      "[143]\ttraining's rmse: 142.891\tvalid_1's rmse: 611.517\n",
      "[144]\ttraining's rmse: 141.722\tvalid_1's rmse: 611.674\n",
      "[145]\ttraining's rmse: 140.728\tvalid_1's rmse: 611.795\n",
      "[146]\ttraining's rmse: 139.597\tvalid_1's rmse: 612.026\n",
      "[147]\ttraining's rmse: 138.502\tvalid_1's rmse: 612.212\n",
      "[148]\ttraining's rmse: 137.367\tvalid_1's rmse: 612.178\n",
      "[149]\ttraining's rmse: 136.326\tvalid_1's rmse: 612.195\n",
      "[150]\ttraining's rmse: 135.328\tvalid_1's rmse: 612.295\n",
      "[151]\ttraining's rmse: 134.157\tvalid_1's rmse: 612.351\n",
      "[152]\ttraining's rmse: 133.066\tvalid_1's rmse: 612.354\n",
      "Early stopping, best iteration is:\n",
      "[142]\ttraining's rmse: 144.062\tvalid_1's rmse: 611.33\n"
     ]
    }
   ],
   "source": [
    "gbm = lgb.train(params,lgb_train,num_boost_round=500,valid_sets=[lgb_train,lgb_eval],early_stopping_rounds=10)\n",
    "\n",
    "yp = gbm.predict(X7_scaler, num_iteration=gbm.best_iteration)\n",
    "yt = Y7['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整体RMSE is:\n",
      "102.0388933441487\n",
      "分数 is:\n",
      "('score', 13.35059190898342, True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error #均方误差\n",
    "print(\"整体RMSE is:\")\n",
    "print(np.sqrt(mean_squared_error(yt/60,yp/60))) #除以60是因为标签为秒，换算成分钟\n",
    "\n",
    "#评价分数\n",
    "def scores(y_true, y_pred):\n",
    "    er = (y_true - y_pred)/60\n",
    "    def apply_each(x):\n",
    "        if(x <= 0):\n",
    "            return np.exp(-np.log(0.5) * (x / 5))\n",
    "        else:\n",
    "            return np.exp(np.log(0.5) * (x / 20))\n",
    "    return 'score', np.array([apply_each(i) for i in er]).mean()*100, True\n",
    "print(\"分数 is:\")\n",
    "print(scores(yt,yp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
