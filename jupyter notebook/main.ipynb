{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DE_time', 'FE_time', 'BA_time', 'RPM']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "params = {}\n",
    "params['n_estimators'] = 100\n",
    "params['max_samples'] ='auto'\n",
    "params['contamination'] = 0.1\n",
    "params['max_features'] = 1.0\n",
    "\n",
    "params['nu'] = 0.001\n",
    "params['gamma']='auto'\n",
    "params['kernel'] ='poly'\n",
    "\n",
    "params['path'] = 'data/train/B01.csv'\n",
    "params['opath'] ='dataclean/B01.csv'\n",
    "try:\n",
    "    with open(params['path'],'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        head_row=next(reader)\n",
    "        data_attribute = []\n",
    "    for item in head_row:\n",
    "        data_attribute.append(item)\n",
    "    print(data_attribute)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.91511018e-01 -3.69818182e-02 -8.20842730e-03  1.79600000e+03]\n",
      " [ 1.50577365e-01  4.49945455e-02 -1.55316320e-02  1.79600000e+03]\n",
      " [-3.68727745e-02 -8.62909091e-03  3.82255193e-03  1.79600000e+03]\n",
      " ...\n",
      " [ 2.42353214e-01 -6.98545455e-03  7.06970920e-02  1.79600000e+03]\n",
      " [ 3.24870259e-03  1.06836364e-02  7.12604154e-02  1.79600000e+03]\n",
      " [-6.22126547e-02 -1.01700000e-01 -2.03198813e-02  1.79600000e+03]]\n",
      "14708\n"
     ]
    }
   ],
   "source": [
    "tn = pd.read_csv(params['path']) \n",
    "tn.dropna(inplace=True)\n",
    "train = np.array(tn)\n",
    "train_x = np.array(train)\n",
    "print(train_x)\n",
    "# clf = IsolationForest(n_estimators=params['n_estimators'], \n",
    "#                       max_samples=params['max_samples'], \n",
    "#                       contamination=params['contamination'], \n",
    "#                       max_features=params['max_features'], \n",
    "#                       bootstrap=False, n_jobs=1, random_state=None, \n",
    "#                       verbose=0).fit(train_x)\n",
    "clf = svm.OneClassSVM(nu=params['nu'],\n",
    "              kernel=params['kernel'],\n",
    "              gamma=params['gamma']).fit(train_x)\n",
    "pred = clf.predict(train_x)\n",
    "print (pred.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14708\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(pd.read_csv(params['path']))[0:pred.size]\n",
    "df['pred']=pred\n",
    "df2 = df[-df.pred.isin([-1])]\n",
    "df2 = df2.drop(['pred'],axis=1)\n",
    "data_out = df2.iloc[:,:].values\n",
    "print(int(df2.size/4))\n",
    "csvfile2 = open(params['opath'],'w',newline='')\n",
    "writer = csv.writer(csvfile2)\n",
    "writer.writerow(data_attribute)   #存属性\n",
    "m=len(data_out)\n",
    "for i in range(m):\n",
    "    writer.writerow(data_out[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7319\n",
      "7328\n",
      "7319\n",
      "7319\n",
      "7345\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats,signal,fftpack\n",
    "import math\n",
    "from pywt import wavedec\n",
    "import traceback\n",
    "import sys\n",
    "columns_list=['time_mean','time_std','time_max','time_min','time_rms','time_ptp','time_median','time_iqr','time_pr','time_skew','time_kurtosis','time_var','time_amp',                'time_smr','time_wavefactor','time_peakfactor','time_pulse','time_margin','freq_mean','freq_std','freq_max','freq_min','freq_rms','freq_median',               'freq_iqr','freq_pr','freq_f2','freq_f3','freq_f4','freq_f5','freq_f6','freq_f7','freq_f8','ener_cA5','ener_cD1','ener_cD2','ener_cD3','ener_cD4',        'ener_cD5','ratio_cA5','ratio_cD1','ratio_cD2','ratio_cD3','ratio_cD4','ratio_cD5']\n",
    "columns_list1 = [a + '_DE' for a in columns_list]\n",
    "columns_list2 = [a + '_FE' for a in columns_list]\n",
    "# columns_list3 = [a + '_BA' for a in columns_list]\n",
    "# columns_list_final = columns_list1 + columns_list2+ columns_list3\n",
    "columns_list_final = columns_list1 + columns_list2\n",
    "params = {}\n",
    "params['len_piece']=100 #窗口长度\n",
    "windowlen=params['len_piece']\n",
    "\n",
    "\n",
    "def feature_get(filepath,windowlen):\n",
    "        df_data = pd.DataFrame(pd.read_csv(filepath))\n",
    "#         dfs = df_data.loc[:,['DE_time','FE_time','BA_time']]\n",
    "        dfs = df_data.loc[:,['DE_time','FE_time']]\n",
    "        features_list=[]\n",
    "        print(len(dfs))\n",
    "        for i in range (0,len(dfs),windowlen):\n",
    "            if(int((len(dfs)-i)/100)>=1): #舍去少量数据\n",
    "                df=dfs[i:i+params['len_piece']]\n",
    "                feature_list = []\n",
    "    #             print(df)\n",
    "                for i in df.columns:\n",
    "                    #----------  time-domain feature,18\n",
    "                    #依次为均值，标准差，最大值，最小值，均方根，峰峰值，中位数，四分位差，百分位差，偏度，峰度，方差，整流平均值，方根幅值，波形因子，峰值因子，脉冲值，裕度\n",
    "                    df_line = df[i]\n",
    "    #                 print(df_line)\n",
    "                    time_mean = df_line.mean()\n",
    "                    time_std = df_line.std()\n",
    "                    time_max = df_line.max()\n",
    "                    time_min = df_line.min()\n",
    "                    time_rms = np.sqrt(np.square(df_line).mean())\n",
    "                    time_ptp = time_max-time_min \n",
    "                    time_median = np.median(df_line)\n",
    "                    time_iqr = np.percentile(df_line,75)-np.percentile(df_line,25)\n",
    "                    time_pr = np.percentile(df_line,90)-np.percentile(df_line,10)\n",
    "                    time_skew = stats.skew(df_line)\n",
    "                    time_kurtosis = stats.kurtosis(df_line)\n",
    "                    time_var = np.var(df_line)\n",
    "                    time_amp = np.abs(df_line).mean()\n",
    "                    time_smr = np.square(np.sqrt(np.abs(df_line)).mean())\n",
    "                    #下面四个特征需要注意分母为0或接近0问题，可能会发生报错\n",
    "                    time_wavefactor = time_rms/time_amp\n",
    "                    time_peakfactor = time_max/time_rms\n",
    "                    time_pulse = time_max/time_amp\n",
    "                    time_margin = time_max/time_smr\n",
    "                    #----------  freq-domain feature,15\n",
    "                    #采样频率25600Hz\n",
    "                    df_fftline = fftpack.fft(df[i])\n",
    "                    freq_fftline = fftpack.fftfreq(len(df[i]),1/25600)\n",
    "                    df_fftline = abs(df_fftline[freq_fftline>=0])\n",
    "                    freq_fftline = freq_fftline[freq_fftline>=0]\n",
    "                    #基本特征,依次为均值，标准差，最大值，最小值，均方根，中位数，四分位差，百分位差\n",
    "                    freq_mean = df_fftline.mean()\n",
    "                    freq_std = df_fftline.std()\n",
    "                    freq_max = df_fftline.max()\n",
    "                    freq_min = df_fftline.min()\n",
    "                    freq_rms = np.sqrt(np.square(df_fftline).mean())\n",
    "                    freq_median = np.median(df_fftline)\n",
    "                    freq_iqr = np.percentile(df_fftline,75)-np.percentile(df_fftline,25)\n",
    "                    freq_pr = np.percentile(df_fftline,90)-np.percentile(df_fftline,10)\n",
    "                    #f2 f3 f4反映频谱集中程度\n",
    "                    freq_f2 = np.square((df_fftline-freq_mean)).sum()/(len(df_fftline)-1)\n",
    "                    freq_f3 = pow((df_fftline-freq_mean),3).sum()/(len(df_fftline)*pow(freq_f2,1.5))\n",
    "                    freq_f4 = pow((df_fftline-freq_mean),4).sum()/(len(df_fftline)*pow(freq_f2,2))\n",
    "                    #f5 f6 f7 f8反映主频带位置\n",
    "                    freq_f5 = np.multiply(freq_fftline,df_fftline).sum()/df_fftline.sum()\n",
    "                    freq_f6 = np.sqrt(np.multiply(np.square(freq_fftline),df_fftline).sum())/df_fftline.sum()\n",
    "                    freq_f7 = np.sqrt(np.multiply(pow(freq_fftline,4),df_fftline).sum())/np.multiply(np.square(freq_fftline),df_fftline).sum()\n",
    "                    freq_f8 = np.multiply(np.square(freq_fftline),df_fftline).sum()/np.sqrt(np.multiply(pow(freq_fftline,4),df_fftline).sum()*df_fftline.sum())\n",
    "                    #----------  timefreq-domain feature,12\n",
    "                    #5级小波变换，最后输出6个能量特征和其归一化能量特征\n",
    "                    cA5, cD5, cD4, cD3, cD2, cD1 = wavedec(df[i], 'db10', level=5)\n",
    "                    ener_cA5 = np.square(cA5).sum()\n",
    "                    ener_cD5 = np.square(cD5).sum()\n",
    "                    ener_cD4 = np.square(cD4).sum()\n",
    "                    ener_cD3 = np.square(cD3).sum()\n",
    "                    ener_cD2 = np.square(cD2).sum()\n",
    "                    ener_cD1 = np.square(cD1).sum()\n",
    "                    ener = ener_cA5 + ener_cD1 + ener_cD2 + ener_cD3 + ener_cD4 + ener_cD5\n",
    "                    ratio_cA5 = ener_cA5/ener\n",
    "                    ratio_cD5 = ener_cD5/ener\n",
    "                    ratio_cD4 = ener_cD4/ener\n",
    "                    ratio_cD3 = ener_cD3/ener\n",
    "                    ratio_cD2 = ener_cD2/ener\n",
    "                    ratio_cD1 = ener_cD1/ener\n",
    "                    feature_list.extend([time_mean,time_std,time_max,time_min,time_rms,time_ptp,time_median,time_iqr,time_pr,time_skew,time_kurtosis,time_var,time_amp,\n",
    "                                     time_smr,time_wavefactor,time_peakfactor,time_pulse,time_margin,freq_mean,freq_std,freq_max,freq_min,freq_rms,freq_median,\n",
    "                                     freq_iqr,freq_pr,freq_f2,freq_f3,freq_f4,freq_f5,freq_f6,freq_f7,freq_f8,ener_cA5,ener_cD1,ener_cD2,ener_cD3,ener_cD4,ener_cD5,\n",
    "                                     ratio_cA5,ratio_cD1,ratio_cD2,ratio_cD3,ratio_cD4,ratio_cD5])\n",
    "                features_list.append(feature_list)\n",
    "        return features_list\n",
    "\n",
    "for i in range(10,15):\n",
    "    params['data_path'] = 'data/train/OR'+str(i)+'.csv'\n",
    "    params['opath'] ='datafeature/OR'+str(i)+'_feature.csv'\n",
    "#     params['data_path'] = 'data/train/NORMAL0'+str(i)+'.csv'\n",
    "#     params['opath'] ='datafeature/NORMAL0'+str(i)+'_feature.csv'\n",
    "    fea = feature_get(params['data_path'],windowlen)\n",
    "    # print(fea)\n",
    "    result = pd.DataFrame(fea,columns = columns_list_final)\n",
    "    result['label']=3\n",
    "    #B:1;IR:2;OR:3;Normal:0.\n",
    "    result.to_csv(params['opath'],index=False,header=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = 'datafeature/B01_feature.csv'  #特征提取后的csv文件路径\n",
    "df = pd.DataFrame(pd.read_csv(path))\n",
    "delete_features = [] #需要删除的列名自行加到数组里\n",
    "df = df.drop(delete_features, axis=1) #特征选择之后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('datafeature/B01_feature.csv')\n",
    "df2 = pd.read_csv('datafeature/B02_feature.csv')\n",
    "df3 = pd.read_csv('datafeature/B03_feature.csv')\n",
    "df4 = pd.read_csv('datafeature/B04_feature.csv')\n",
    "df5 = pd.read_csv('datafeature/B05_feature.csv')\n",
    "df_fault = pd.concat([df1,df2,df3,df4,df5])\n",
    "df_fault = df_fault.reset_index(drop=True)\n",
    "df_fault.to_csv('data_faultB.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B01_feature.csv', 'B02_feature.csv', 'B03_feature.csv', 'B04_feature.csv', 'B05_feature.csv', 'B06_feature.csv', 'IR01_feature.csv', 'IR02_feature.csv', 'IR03_feature.csv', 'IR04_feature.csv', 'IR05_feature.csv', 'IR06_feature.csv', 'NORMAL01_feature.csv', 'NORMAL02_feature.csv', 'OR01_feature.csv', 'OR02_feature.csv', 'OR03_feature.csv', 'OR04_feature.csv', 'OR05_feature.csv', 'OR06_feature.csv', 'OR07_feature.csv', 'OR08_feature.csv', 'OR09_feature.csv', 'OR10_feature.csv', 'OR11_feature.csv', 'OR12_feature.csv', 'OR13_feature.csv', 'OR14_feature.csv']\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "filePath='datafeature'\n",
    "outputfile='train.csv'\n",
    "fileList = os.listdir(filePath)\n",
    "# print(fileList)\n",
    "# print(len(fileList))\n",
    "path = os.path.join(filePath, fileList[0])\n",
    "df = pd.read_csv(path)\n",
    "df.to_csv(outputfile,index=False, header=True)\n",
    "for i in range (1,len(fileList)):\n",
    "    path = os.path.join(filePath, fileList[i])\n",
    "#     print(path)\n",
    "    df = pd.read_csv(path)\n",
    "    df.to_csv(outputfile, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import joblib\n",
    "def train():\n",
    "    # 模型初始化，设置random_state保证可复现性，便于观察优化\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    train_data_y = train_data['label']\n",
    "    # 除去标签的所有列就是特征\n",
    "    train_data_x = train_data.drop(['label'], axis=1)\n",
    "    model_lgb_default = lgb.LGBMClassifier(random_state=2019)\n",
    "    # 模型训练\n",
    "    model_lgb_default.fit(train_data_x, train_data_y)\n",
    "    joblib.dump(model_lgb_default, 'model/lightgbm_model.model')\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lightgbm():\n",
    "    # 加载模型\n",
    "    model = joblib.load('model/lightgbm_model.model')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
